{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Session 03: Find near-duplicates using shingling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will take a large corpus of tweets and detect near-duplicates on this corpus using a technique known as *shingling*.\n",
    "\n",
    "Two documents are considered near-duplicates if they share a large amount of ngrams. The *ngrams* of a phrase are overlapping sequences of words of length *n*. For instance, the phrase '*Never let them guess your next move.*' has the following 3-grams:\n",
    "\n",
    "* 'never let them'\n",
    "* 'let them guess'\n",
    "* 'them guess your'\n",
    "* 'guess your next'\n",
    "* 'your next move'\n",
    "\n",
    "To measure the similarity between two sets, we will use the [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index), which is the size of the intersection of the two sets divided by their union. This values goes between 0.0 (meaning the documents have no ngrams in common) to 1.0 (meaning the documents have the same ngrams).\n",
    "\n",
    "To speed up things, instead of comparing the set of shingles of two documents which can be large, we will derive a fixed-length *signature* or *sketch* for each document. This will be obtained by (1) applying a random permutation to the list of possible ngrams, and (2) pick the ngram that appears first in the permuted list. The Jaccard index between these signatures will be a good approximation of the Jaccard index between the original sets of ngrams. \n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: <font color=\"blue\">Josip Hanak</font>\n",
    "\n",
    "E-mail: <font color=\"blue\">josip.hanak@fer.hr</font>\n",
    "\n",
    "Date: <font color=\"blue\">14/10/2022</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset\n",
    "\n",
    "The corpus you will use contains about 35,500 messages (\"tweets\") posted between March 13th, 2020, and March 14th, 2020, containing a hashtag or keyword related to COVID-19, and posted by a user declaring a location in Catalonia.\n",
    "\n",
    "The tweets are in a format known as [JSON](https://en.wikipedia.org/wiki/JSON#Example). Python's JSON library takes care of translating it into a dictionary.\n",
    "\n",
    "Then, the file is compressed using `gzip`, and can be compressed with the `gunzip` command, although we will read it in compressed form. The file is named `CovidLockdownCatalonia.json.gz`.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import gzip\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 10000 documents\n"
     ]
    }
   ],
   "source": [
    "# Input file\n",
    "INPUT_FILENAME = \"CovidLockdownCatalonia.json.gz\"\n",
    "\n",
    "# Array for storing messages\n",
    "messages = []\n",
    "MAX_MESSAGES = 10000\n",
    "\n",
    "with gzip.open(INPUT_FILENAME, \"rt\", encoding=\"utf-8\") as input_file:\n",
    "    \n",
    "    messages_read = 0\n",
    "    for line in input_file:\n",
    "            \n",
    "        # Read message\n",
    "        tweet = json.loads(line)\n",
    "\n",
    "        # Keep only messages in Catalan\n",
    "        if tweet[\"lang\"] == \"ca\":\n",
    "            \n",
    "            messages_read += 1\n",
    "            \n",
    "            if messages_read <= MAX_MESSAGES:\n",
    "                author = tweet[\"user\"][\"screen_name\"]\n",
    "                message = tweet[\"full_text\"]\n",
    "                messages.append(message)\n",
    "\n",
    "print(\"Read %d documents\" % len(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the Jaccard similarity between two lists: the size of the intersection of two sets, divided by the size of their union.\n",
    "\n",
    "You can use set operations: `set(l)` to convert a list `l` to a set, then `set1.union(set2)` and `set1.intersection(set2)` to compute union and intersection of sets `set1`, `set2`. Learn more in this [tutorial on set operations](https://learnpython.com/blog/python-set-operations/)\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for function \"jaccard_similarity\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(x, y):\n",
    "    set1 = set(x)\n",
    "    set2 = set(y)\n",
    "    union = set1.union(set2)\n",
    "    intersect = set1.intersection(set2)\n",
    "    if len(union)>0:\n",
    "        return len(intersect)/len(union)\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to test your function. Your tests cases should be:\n",
    "\n",
    "1. Two arrays for which the jaccard similarity is 0.6666...\n",
    "1. Two arrays for which the jaccard similarity is 0.75\n",
    "1. Two arrays for which the jaccard similarity is 1.0\n",
    "1. Two empty arrays should have jaccard similarity 0.0\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code testing \"jaccard_similarity\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.75\n",
      "0.0\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "listA = [\"i\", \"love\", \"data\"]\n",
    "listB = [\"love\", \"data\", \"i\"]\n",
    "print(jaccard_similarity(listA, listB))\n",
    "listC = [\"i\", \"love\", \"data\", \"not\"]\n",
    "print(jaccard_similarity(listA, listC))\n",
    "listD = [\"everything\", \"said\", \"has\", \"been\", \"lie\"]\n",
    "print(jaccard_similarity(listA, listD))\n",
    "listE = [\"lie\", \"has\", \"been\", \"normal\", \"everything\"]\n",
    "print(jaccard_similarity(listD, listE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function `clean` that cleans-up text according to this specification:\n",
    "\n",
    "1. Removing \"RT \" prefixes\n",
    "1. Converting to lowercase\n",
    "1. [Romanizing](https://en.wikipedia.org/wiki/Romanization) text, replacing \"Ñ\" by \"n\", \"ñ\" by \"n\", \"ó\" by \"o\", \"à\" by \"a\", \"l·l\" by \"ll\", and so on.\n",
    "1. Removing URLs, both \"http\" and \"https\" ones.\n",
    "1. Removing spaces at the beginning and spaces at the end with the `strip()` function.\n",
    "1. Removing anything that remains that is not a letter or digit\n",
    "1. Changing double spaces to single spaces.\n",
    "\n",
    "You can use `text.lower()` to convert to lowercase, and then `re.sub(...)` to replace parts of the text. See [Python regexps](https://docs.python.org/3/library/re.html).\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for function \"clean\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "def clean(text):\n",
    "    if text.startswith(\"RT\"):\n",
    "        text =  text[2:]\n",
    "    text = unicode(text)\n",
    "    text = text.lower().strip()\n",
    "    text = text.replace(\"http\",\"\")\n",
    "    text = text.replace(\"https\",\"\")\n",
    "    text = re.sub(' +', ' ',text) \n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]+', '', text)\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function by passing it five different texts including punctuation, non-Roman characters, URLs, etc. Make sure your test cases cover all the required aspects of the specification.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code testing function \"clean\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babamisatamrt\n",
      "a is a rtb\n",
      "alfa and sbeta\n",
      "ajme meni rt majko moja\n"
     ]
    }
   ],
   "source": [
    "#testing lowercase\n",
    "text = clean(\"BabaMISaTamRT\")\n",
    "print(text)\n",
    "#testing RT prefix\n",
    "text = clean(\"RTa is a  RTb\")\n",
    "print(text)\n",
    "#testing http and https\n",
    "text = clean(\"http//alfahttp and https//beta\")\n",
    "print(text)\n",
    "#testing non roman literals\n",
    "\n",
    "#testing non digit or letter literals\n",
    "text = clean(\"!!ajme meni, RT majko moj=?!a\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implement an n-gram extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function `ngrams(text,size)`, which should produce all sub-sequences of `size` words present in the text. Use the following skeleton:\n",
    "\n",
    "```python\n",
    "MIN_TOKEN_LENGTH = 2\n",
    "\n",
    "def ngrams(text, size):\n",
    "    tokens = clean(text).split()\n",
    "    ngrams = []\n",
    "    # your code here\n",
    "    return ngrams\n",
    "```\n",
    "\n",
    "Note that `ngrams` is a list, and each element of a list is a *string*.\n",
    "\n",
    "The only words you must consider in a ngram are words having at least `MIN_TOKEN_LENGTH` characters.\n",
    "\n",
    "You can use the [split](https://docs.python.org/2/library/string.html#string.split) and [join](https://docs.python.org/2/library/string.html#string.join) function of the split library. Remember that to extract elements *i* to *j* of array *a* you use `a[i:j]`.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code implementing function \"ngrams(text,size)\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_TOKEN_LENGTH = 2\n",
    "def ngrams(text, size):\n",
    "    tokens = clean(text).split()\n",
    "    tokens = [item for item in tokens if len(item) >= 2]\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens)-size):\n",
    "        j = i+size\n",
    "        ngram = []\n",
    "        ngram = tokens[i:j]\n",
    "        ngram = ' '.join(ngram)\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function:\n",
    "\n",
    "```python\n",
    "print(messages[9780])\n",
    "print(ngrams(messages[9780], 2))\n",
    "```\n",
    "\n",
    "Should print:\n",
    "\n",
    "```\n",
    "RT @diariARA: Comerciants xinesos donen mascaretes i gel antisèptic a Badalona per lluitar contra el coronavirus https://t.co/ybYXFxphIu\n",
    "['diariara comerciants', 'comerciants xinesos', 'xinesos donen', 'donen mascaretes', 'mascaretes gel', 'gel antiseptic', 'antiseptic badalona', 'badalona per', 'per lluitar', 'lluitar contra', 'contra el', 'el coronavirus']\n",
    "```\n",
    "\n",
    "Remember that `ngrams` should return a list of string, not a list of lists, so carefully check that you are returning a list of strings and not a list of lists.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code testing function \"ngrams\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @diariARA: Comerciants xinesos donen mascaretes i gel antisèptic a Badalona per lluitar contra el coronavirus https://t.co/ybYXFxphIu\n",
      "['diariara comerciants', 'comerciants xinesos', 'xinesos donen', 'donen mascaretes', 'mascaretes gel', 'gel antisptic', 'antisptic badalona', 'badalona per', 'per lluitar', 'lluitar contra', 'contra el', 'el coronavirus']\n"
     ]
    }
   ],
   "source": [
    "print(messages[9780])\n",
    "print(ngrams(messages[9780], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estimation for brute force method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code, which you should leave as-is, computes the time it takes to compare all first *limit* messages against all first *limit* messages in the array.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEAVE AS-IS\n",
    "\n",
    "def time_brute_force_similarities(messages, limit, ngram_size):\n",
    "    if limit > len(messages):\n",
    "        raise ValueError(\"Limit should be less than or equal than the number of messages\")\n",
    "        \n",
    "    # Start a timer\n",
    "    start = timer()\n",
    "\n",
    "    # Iterate through document identifiers\n",
    "    for docid1 in range(np.min([len(messages), limit])):\n",
    "\n",
    "        # Clean document 1 and extract ngrams\n",
    "        doc1 = clean(messages[docid1])\n",
    "        ngrams1 = ngrams(doc1, ngram_size)\n",
    "\n",
    "        # Iterate through document identifiers larger than doc2\n",
    "        for docid2 in range(docid1+1, np.min([len(messages), limit])):\n",
    "                         \n",
    "            # Clean document 2 and extract ngrams\n",
    "            doc2 = clean(messages[docid2])\n",
    "            ngrams2 = ngrams(doc2, ngram_size)\n",
    "\n",
    "            # Compute similarity\n",
    "            similarity = jaccard_similarity(ngrams1, ngrams2)\n",
    "\n",
    "    end = timer()\n",
    "    return(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to create a plot in which you have in the x axis the number of messages to check, and in the y axis the time it takes to check that many messages if we use ngrams of size 3. Try with x from *1* to *2001* in increments of *150* (use the [range](https://docs.python.org/3/library/functions.html#func-range) function).\n",
    "\n",
    "In this plot, remember to include labels in both axes.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for generating the requested plot. Remember to label the x and y axis.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.980006143450737e-05\n",
      "0.6774516999721527\n",
      "2.7850711001083255\n",
      "6.087803700007498\n",
      "10.544664799934253\n",
      "17.651897500036284\n",
      "25.233208799967542\n",
      "34.50250809988938\n",
      "44.802438700105995\n",
      "55.25425019999966\n",
      "71.55880200001411\n",
      "89.65524969995022\n",
      "99.09163440018892\n",
      "115.63906170008704\n",
      "{1: 0.0001970999874174595, 151: 0.6127774999476969, 301: 2.7442266999278218, 451: 6.02620070008561, 601: 10.73564779991284, 751: 17.09892479982227, 901: 26.333338900003582, 1051: 34.56404000008479, 1201: 45.556621899828315, 1351: 57.69637449993752, 1501: 69.5631135001313, 1651: 89.3131572001148, 1801: 104.69473390001804, 1951: 114.7669877000153}\n"
     ]
    }
   ],
   "source": [
    "message_num_time = dict()\n",
    "for num_messages in range(1,2001,150):\n",
    "    message_num_time[num_messages] = time_brute_force_similarities(messages, num_messages, 3)\n",
    "    print(time_brute_force_similarities(messages, num_messages, 3))\n",
    "print(message_num_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(list(message_num_time.keys()), message_num_time.values(), width=100, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with (1) a brief commmentary about what you see in this plot, and (2) your estimate for how long it would take to run the brute force similarity computations for the entire input matrix. Express your estimation in hours, minutes, and seconds. Justify precisely your calculations.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If the data set contains 10000 messages (documents) that is 5 times the size of what is given to the algorithm \n",
    "(which takes around 2 minutes to complete). As shown in the graph the time increases in a way similar to a quadratic function \n",
    "(taking 150 messages difference as x values). The difference between the whole dataset and the previously calculated dataset \n",
    "is 53 bins of 150 messages. I would approximate that for the whole dataset it would take 3574 seconds which is 0.99 of an hour\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Computing the doc-ngram matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute a matrix in which every row is an ngram, and every column is a document.\n",
    "\n",
    "In real-world implementations, this is done by hashing the ngrams and then every row is an ngram *hash*; in this practice we will skip that step and work directly with one ngram per row, which is conceptually the same and easier to code.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Create list of all ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement code to create:\n",
    "\n",
    "* the dictionary `ngram_to_index`, which should convert an ngram to an index (a row number),\n",
    "* the dictionary `index_to_ngram`, which should convert an index to an ngram, and\n",
    "* the variable `num_distinct_ngrams` which should contain the number of distinct ngrams.\n",
    "\n",
    "You can use the following template:\n",
    "\n",
    "```python\n",
    "NGRAM_SIZE = 3\n",
    "\n",
    "ngram_to_index = {}\n",
    "index_to_ngram = {}\n",
    "next_index = 0\n",
    "\n",
    "for message in messages:\n",
    "    all_ngrams = ngrams(message, NGRAM_SIZE)\n",
    "    for ngram in all_ngrams:\n",
    "        # YOUR CODE HERE\n",
    "            \n",
    "num_distinct_ngrams = next_index\n",
    "\n",
    "print(\"There are %d distinct ngrams in the %d documents\" % (num_distinct_ngrams, len(messages)))\n",
    "```\n",
    "\n",
    "Note that the total number of n-grams may vary depending on ho you `clean()` text. In this dataset it should be about 10 times the number of documents.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for creating the ngram_to_index dictionary.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 63948 distinct ngrams in the 10000 documents\n"
     ]
    }
   ],
   "source": [
    "NGRAM_SIZE = 3\n",
    "\n",
    "ngram_to_index = dict()\n",
    "index_to_ngram = dict()\n",
    "index = 0\n",
    "\n",
    "for message in messages:\n",
    "    all_ngrams = ngrams(message, NGRAM_SIZE)\n",
    "    for ngram in all_ngrams:\n",
    "        if ngram not in ngram_to_index.keys():\n",
    "            ngram_to_index[ngram] = index\n",
    "            index_to_ngram[index] = ngram\n",
    "            index=index+1\n",
    "        \n",
    "\n",
    "num_distinct_ngrams = index\n",
    "print(\"There are %d distinct ngrams in the %d documents\" % (num_distinct_ngrams, len(messages)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function by printing the `ngram_to_index` of the strings `\"tancat escoles fins\"` and `\"garantir la seguretat\"`. The exact index varies,  depending on how you `clean()` text. Then, print the `index_to_ngram` of the returned index, and should give you the same string.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for testing the ngram_to_index structure.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 888\n",
      "tancat escoles fins garantir la seguretat\n"
     ]
    }
   ],
   "source": [
    "print(ngram_to_index[\"garantir la seguretat\"], ngram_to_index[\"tancat escoles fins\"])\n",
    "print(index_to_ngram[ngram_to_index[\"tancat escoles fins\"]], index_to_ngram[ngram_to_index[\"garantir la seguretat\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create table ngrams x documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a boolean matrix named `M_ngram_doc`, where each row should be an n-gram, and each column should be a document.\n",
    "\n",
    "There might be documents having less than *NGRAM_SIZE* words and thus containing no shingles. You can skip those documents above (when reading the file), or handle them here.\n",
    "\n",
    "The next code creates an empty matrix. Leave as-is. If you run out of memory, limit the number of documents you read at the beginning of this file, for instance, read only the first 10,000 or the first 7,000 documents, and then try again.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions: 63948 rows (distinct shingles) x 10000 columns (distinct documents)\n"
     ]
    }
   ],
   "source": [
    "# LEAVE AS-IS\n",
    "\n",
    "# Create dense matrix in which every cell contains the value \"False\"\n",
    "M_ngram_doc = np.full((num_distinct_ngrams, len(messages)), False)\n",
    "\n",
    "# Print the number of rows and columns of this matrix\n",
    "# numpy.matrix.shape is a tuple, shape[0] is the number of rows, shape[1] the number of columns\n",
    "print(\"Matrix dimensions: %d rows (distinct shingles) x %d columns (distinct documents)\" % M_ngram_doc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the matrix `M_ngram_doc` so that position i, j (row, column) holds a `True` if document j contains ngram i, otherwise holds `False`.\n",
    "\n",
    "You can use the following template:\n",
    "\n",
    "```python\n",
    "for docid in range(len(messages)):\n",
    "    message = messages[docid]\n",
    "    all_ngrams = ngrams(message, ngram_size)\n",
    "    for ngram in all_ngrams:\n",
    "        # replace this comment with your code\n",
    "```\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for filling the M_ngram_doc matrix.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAM_SIZE = 3\n",
    "for docid in range(len(messages)):\n",
    "    message = messages[docid]\n",
    "    all_ngrams = ngrams(message, NGRAM_SIZE)\n",
    "    for ngram in all_ngrams:\n",
    "        M_ngram_doc[ngram_to_index[ngram]][docid] = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the density of this matrix, as a percentage. This is the number of non-zeroes in the matrix as a percentage of the number of cells of the matrix.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for printing the density of the M_ngram_doc matrix as a percentage.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023062488271720773\n"
     ]
    }
   ],
   "source": [
    "shape = M_ngram_doc.shape\n",
    "size = shape[0]*shape[1]\n",
    "density = (np.count_nonzero(M_ngram_doc)/size)*100\n",
    "print(density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a couple of documents (columns). All columns should be very sparse, i.e., mostly zeroes. For instance, for docid 9602 you should print something like this:\n",
    "\n",
    "```\n",
    "Positions of non-zeros in column of docid 9602 of M_ngram_doc\n",
    "\n",
    "Clean message:\n",
    " emergenciescat que puc fer i que no faqs del coronavirus a 14 de mar si us plau demanem difusioNon-zeros in corresponding row:\n",
    " emergenciescat que puc fer i que no faqs del coronavirus a 14 de mar si us plau demanem difusio\n",
    " \n",
    "Non-zeros in corresponding row:\n",
    " ['911 (si us plau)', '1222 (emergenciescat que puc)', '1223 (que puc fer)', '1224 (puc fer que)', '1225 (fer que no)', '2575 (14 de mar)', '39134 (que no faqs)', '39135 (no faqs del)', '39136 (faqs del coronavirus)', '39137 (del coronavirus 14)', '39138 (coronavirus 14 de)', '39139 (de mar si)', '39140 (mar si us)', '39141 (us plau demanem)', '39142 (plau demanem difusio)']\n",
    " ```\n",
    "\n",
    "Note that the specific ngram ids you will get depend on your cleanup process, and that the output is in ascending order of ngram number, not in the same ordering in which the ngrams appear in the message.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for printing rows 9602 and 941 of the M_ngram_doc matrix.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861 ( si us plau )\n",
      "1161 ( emergenciescat qu puc )\n",
      "1162 ( qu puc fer )\n",
      "2448 ( 14 de mar )\n",
      "24227 ( fer que no )\n",
      "37368 ( puc fer que )\n",
      "37369 ( que no faqs )\n",
      "37370 ( no faqs del )\n",
      "37371 ( faqs del coronavirus )\n",
      "37372 ( del coronavirus 14 )\n",
      "37373 ( coronavirus 14 de )\n",
      "37374 ( de mar si )\n",
      "37375 ( mar si us )\n",
      "37376 ( us plau demanem )\n",
      "37377 ( plau demanem difusi )\n",
      "\n",
      "1403 ( usem de forma )\n",
      "1404 ( de forma responsable )\n",
      "1405 ( forma responsable els )\n",
      "1406 ( responsable els recursos )\n",
      "1407 ( els recursos sanitaris061 )\n",
      "1408 ( recursos sanitaris061 urgncies )\n",
      "1409 ( sanitaris061 urgncies per )\n",
      "1410 ( urgncies per coronavirus )\n",
      "1411 ( per coronavirus sanitries012 )\n",
      "1412 ( coronavirus sanitries012 consultes )\n",
      "9738 ( hospiolot usem de )\n",
      "RT @hospiolot: ❕Usem de forma responsable els recursos sanitaris:\n",
      "\n",
      "📞061➡️ Urgències per #coronavirus i sanitàries\n",
      "\n",
      "📞012➡️ Consultes general…\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indexes1 = np.array(np.nonzero(M_ngram_doc[:,9602]))\n",
    "indexes2 = np.array(np.nonzero(M_ngram_doc[:,941]))\n",
    "#print(indexes1[0])\n",
    "#print(indexes2[0])\n",
    "for index in indexes1[0]:\n",
    "    print(index, \"(\", index_to_ngram[index], \")\")\n",
    "print()\n",
    "for index in indexes2[0]:\n",
    "    print(index, \"(\", index_to_ngram[index], \")\")\n",
    "print(messages[941])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implement a permutation generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function `random_permutation(k)`, which should generate a random permutation of the array `[0, 2, 3, ..., k-1]`. Tip: the function [random.shuffle](https://docs.python.org/3/library/random.html#random.shuffle) might be useful. If you want to use `range(...)`, which returns an iterator, you will need to convert the iterator to a list by using `list(range(...))`.\n",
    "\n",
    "Remember to test your code. For instance, a permutation of 20 elements should look like this:\n",
    "\n",
    "```\n",
    "[14, 10, 0, 8, 4, 12, 5, 19, 6, 9, 15, 13, 16, 2, 17, 11, 7, 3, 18, 1]\n",
    "```\n",
    "\n",
    "Every number appears only once, and all numbers from 0 to 19 appear in the permutation.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for \"random_permutation\"</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 1, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "def random_permutation(k):\n",
    "    mylist = list(range(0,k))\n",
    "    random.shuffle(mylist)\n",
    "    fin = list(mylist)\n",
    "    return fin\n",
    "\n",
    "print(random_permutation(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further test this by applying the same permutation on two lists. The code below, which you must leave as-is,  should print both lists in the same ordering, so that *alpha* is in the same position of *a*, *beta* in the same position as *b*, and so on.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test one permutation:\n",
      "['1 (ek)', '2 (do)', '5 (pāṅc)', '3 (tīn)', '4 (chār)']\n",
      "['1 (jedan)', '2 (dva)', '5 (pet)', '3 (tri)', '4 (četiri)']\n",
      "\n",
      "Test another permutation\n",
      "['4 (chār)', '2 (do)', '3 (tīn)', '5 (pāṅc)', '1 (ek)']\n",
      "['4 (četiri)', '2 (dva)', '3 (tri)', '5 (pet)', '1 (jedan)']\n"
     ]
    }
   ],
   "source": [
    "# LEAVE AS-IS\n",
    "\n",
    "# Permute a list according to a permutation\n",
    "def permuter(original_list, permutation):\n",
    "    permuted_list = []\n",
    "    for index in permutation:\n",
    "        permuted_list.append(original_list[index])\n",
    "    return permuted_list\n",
    "\n",
    "# Code for testing permutations\n",
    "original_list_1 = [\"1 (ek)\", \"2 (do)\", \"3 (tīn)\", \"4 (chār)\", \"5 (pāṅc)\"]\n",
    "original_list_2 = [\"1 (jedan)\", \"2 (dva)\", \"3 (tri)\", \"4 (četiri)\", \"5 (pet)\"]\n",
    "\n",
    "print(\"Test one permutation:\")\n",
    "permutation_1 = random_permutation(5)\n",
    "print(permuter(original_list_1, permutation_1))\n",
    "print(permuter(original_list_2, permutation_1))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Test another permutation\")\n",
    "permutation_2 = random_permutation(5)\n",
    "print(permuter(original_list_1, permutation_2))\n",
    "print(permuter(original_list_2, permutation_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compute the signature of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the core of the algorithm. We will create a new matrix `M_signature_doc` having a small number of rows (the *signature size*), which will be equivalent to the number of permutations we use. The number of columns will continue being the number of documents.\n",
    "\n",
    "First, we create the permutations and store them in an array of arrays named `permutations`, with the following code, which you should leave as-is.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63948\n",
      "Permutation 0: 17892, 28993, 27511, ...\n",
      "63948\n",
      "Permutation 1: 27740, 3456, 20882, ...\n",
      "63948\n",
      "Permutation 2: 18002, 32798, 51975, ...\n",
      "63948\n",
      "Permutation 3: 50038, 10127, 46791, ...\n",
      "63948\n",
      "Permutation 4: 42474, 51397, 839, ...\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "NUM_PERMUTATIONS = 5\n",
    "\n",
    "permutations = []\n",
    "\n",
    "# Create the permutations\n",
    "for i in range(NUM_PERMUTATIONS):\n",
    "    permutation = random_permutation(num_distinct_ngrams)\n",
    "    #permutations.append(random_permutation(num_distinct_ngrams))\n",
    "    permutations.append(permutation)\n",
    "    \n",
    "# Visualize the permutations by printing their first 3 elements\n",
    "for i in range(len(permutations)):\n",
    "    permutation = permutations[i]\n",
    "    print(\"Permutation %d: %d, %d, %d, ...\" % (i, permutation[0], permutation[1], permutation[2] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you implement the signature construction. The matrix `M_signature_doc` should contain in row *i*, column *j*, the first ngram (the \"minimum\" one) that is present in a column (document), according to the order given by a permutation.\n",
    "\n",
    "This process may take a few minutes to be completed. You can use the following template:\n",
    "\n",
    "```python\n",
    "M_signature_doc = np.full((NUM_PERMUTATIONS, len(messages)), np.nan)\n",
    "\n",
    "# Find the first ngram in a document, according to a permutation\n",
    "def find_first_one(docid, permutation):\n",
    "    for shingle_id in permutation:\n",
    "        if M_ngram_doc[shingle_id, docid] == True:\n",
    "            return shingle_id\n",
    "    return -1\n",
    "\n",
    "# Create permutations\n",
    "for permutation_num in range(NUM_PERMUTATIONS):\n",
    "    print(\"Creating signatures for permutation %d/%d\" % (permutation_num+1, NUM_PERMUTATIONS))\n",
    "    permutation = permutations[permutation_num]\n",
    "    for docid in range(len(messages)):\n",
    "        if docid % 1000 == 0:\n",
    "            print(\"- Scanning document %d of %d\" % (docid, len(messages)))\n",
    "        # replace this comment with your code\n",
    "```\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for creating M_signature_doc</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating signatures for permutation 1/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n",
      "Creating signatures for permutation 2/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n",
      "Creating signatures for permutation 3/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n",
      "Creating signatures for permutation 4/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n",
      "Creating signatures for permutation 5/5\n",
      "- Scanning document 0 of 10000\n",
      "- Scanning document 1000 of 10000\n",
      "- Scanning document 2000 of 10000\n",
      "- Scanning document 3000 of 10000\n",
      "- Scanning document 4000 of 10000\n",
      "- Scanning document 5000 of 10000\n",
      "- Scanning document 6000 of 10000\n",
      "- Scanning document 7000 of 10000\n",
      "- Scanning document 8000 of 10000\n",
      "- Scanning document 9000 of 10000\n"
     ]
    }
   ],
   "source": [
    "M_signature_doc = np.full((NUM_PERMUTATIONS, len(messages)), np.nan)\n",
    "\n",
    "# Find the first ngram in a document, according to a permutation\n",
    "def find_first_one(docid, permutation):\n",
    "    for shingle_id in permutation:\n",
    "        if M_ngram_doc[shingle_id, docid] == True:\n",
    "            return shingle_id\n",
    "    return -1\n",
    "\n",
    "# Create permutations\n",
    "for permutation_num in range(NUM_PERMUTATIONS):\n",
    "    print(\"Creating signatures for permutation %d/%d\" % (permutation_num+1, NUM_PERMUTATIONS))\n",
    "    permutation = permutations[permutation_num]\n",
    "    for docid in range(len(messages)):\n",
    "        if docid % 1000 == 0:\n",
    "            print(\"- Scanning document %d of %d\" % (docid, len(messages)))\n",
    "        # replace with code\n",
    "        M_signature_doc[permutation_num][docid]=find_first_one(docid,permutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code by checking the signatures of two documents that are near-duplicates,using the next code, which you should leave as-is. Being near-duplicates, we expect these should have many ngrams in common, and hence, with high probability they will have many elements in common in their signatures.\n",
    "\n",
    "Note that your ngrams and signatures vectors might be different than what we show here, given the differences in cleaning procedures and the randomness of the permutations.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #385\n",
      "Message       : RT @gencat: 🔴 El @govern de la @gencat anuncia el #confinament de tot Catalunya.\n",
      "\n",
      "Davant l’emergència de la #COVID19, el missatge és clau:…\n",
      "Clean message : gencat  el govern de la gencat anuncia el confinament de tot catalunyadavant lemergncia de la covid19 el missatge s clau\n",
      "Ngrams        : [57, 3179, 3295, 3896, 4655, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666]\n",
      "Signature     : [4657.0, 3295.0, 4657.0, 57.0, 4658.0]\n",
      "\n",
      "Document #627\n",
      "Message       : PROCICAT_CORONAVIRUS. El @govern de la @gencat anuncia el #confinament de tot Catalunya. Davant l’emergència de la #COVID19, el missatge és clau: limitar la mobilitat ajudarà a evitar la propagació del #coronavirus. Evitem desplaçaments i reduïm la vida social #JoEmQuedoACasa\n",
      "Clean message : procicatcoronavirus el govern de la gencat anuncia el confinament de tot catalunya davant lemergncia de la covid19 el missatge s clau limitar la mobilitat ajudar a evitar la propagaci del coronavirus evitem desplaaments i redum la vida social joemquedoacasa\n",
      "Ngrams        : [57, 3179, 3295, 3896, 4655, 4656, 4657, 4658, 4659, 4660, 4661, 4662, 4663, 4664, 4665, 4666]\n",
      "Signature     : [4657.0, 3295.0, 4657.0, 57.0, 4658.0]\n"
     ]
    }
   ],
   "source": [
    "# Leave this code as-is\n",
    "\n",
    "def extract_ngrams(docid):\n",
    "    return [x for x in range(num_distinct_ngrams) if M_ngram_doc[x, i] == True]\n",
    "\n",
    "def extract_signature(docid):\n",
    "    return [M_signature_doc[x, docid] for x in range(NUM_PERMUTATIONS)]\n",
    "\n",
    "def print_sig(messages, M_ngram_doc, M_signature_doc, i):\n",
    "    print(\"Document #%d\" % i)\n",
    "    print(\"Message       : %s\" % messages[i])\n",
    "    print(\"Clean message : %s\" % clean(messages[i]))\n",
    "    print(\"Ngrams        : %s\" % extract_ngrams(i))\n",
    "    print(\"Signature     : %s\" % extract_signature(i))\n",
    "\n",
    "        \n",
    "i = 385\n",
    "j = 627\n",
    "\n",
    "print_sig(messages, M_ngram_doc, M_signature_doc, i )\n",
    "\n",
    "print()\n",
    "\n",
    "print_sig(messages, M_ngram_doc, M_signature_doc, j )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Compare all pairs of signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with your code for comparing all signatures; print all documents that have at least 50 signature matches, considering both full matches and partial matches.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10000 documents scanned\n",
      "16    full matches: 89     partial matches: 2\n",
      "20    full matches: 28     partial matches: 55\n",
      "42    full matches: 46     partial matches: 6\n",
      "53    full matches: 57     partial matches: 0\n",
      "84    full matches: 88     partial matches: 2\n",
      "85    full matches: 45     partial matches: 6\n",
      "128    full matches: 44     partial matches: 6\n",
      "166    full matches: 56     partial matches: 0\n",
      "167    full matches: 55     partial matches: 0\n",
      "168    full matches: 54     partial matches: 0\n",
      "172    full matches: 53     partial matches: 0\n",
      "174    full matches: 52     partial matches: 0\n",
      "176    full matches: 51     partial matches: 0\n",
      "268    full matches: 50     partial matches: 0\n",
      "307    full matches: 87     partial matches: 2\n",
      "328    full matches: 65     partial matches: 0\n",
      "331    full matches: 64     partial matches: 0\n",
      "394    full matches: 27     partial matches: 52\n",
      "412    full matches: 63     partial matches: 0\n",
      "425    full matches: 86     partial matches: 2\n",
      "448    full matches: 62     partial matches: 0\n",
      "500/10000 documents scanned\n",
      "578    full matches: 56     partial matches: 0\n",
      "587    full matches: 55     partial matches: 0\n",
      "620    full matches: 85     partial matches: 2\n",
      "688    full matches: 84     partial matches: 2\n",
      "743    full matches: 54     partial matches: 0\n",
      "793    full matches: 61     partial matches: 0\n",
      "851    full matches: 83     partial matches: 2\n",
      "939    full matches: 82     partial matches: 2\n",
      "964    full matches: 53     partial matches: 0\n",
      "981    full matches: 26     partial matches: 50\n",
      "982    full matches: 60     partial matches: 0\n",
      "989    full matches: 25     partial matches: 50\n",
      "991    full matches: 59     partial matches: 0\n",
      "992    full matches: 58     partial matches: 0\n",
      "998    full matches: 52     partial matches: 0\n",
      "1000/10000 documents scanned\n",
      "1009    full matches: 57     partial matches: 0\n",
      "1030    full matches: 81     partial matches: 2\n",
      "1034    full matches: 24     partial matches: 50\n",
      "1035    full matches: 80     partial matches: 2\n",
      "1069    full matches: 79     partial matches: 2\n",
      "1119    full matches: 78     partial matches: 2\n",
      "1174    full matches: 77     partial matches: 2\n",
      "1213    full matches: 76     partial matches: 2\n",
      "1214    full matches: 23     partial matches: 50\n",
      "1221    full matches: 75     partial matches: 2\n",
      "1224    full matches: 22     partial matches: 50\n",
      "1231    full matches: 51     partial matches: 0\n",
      "1362    full matches: 50     partial matches: 0\n",
      "1401    full matches: 74     partial matches: 2\n",
      "1432    full matches: 73     partial matches: 2\n",
      "1474    full matches: 56     partial matches: 0\n",
      "1500/10000 documents scanned\n",
      "1504    full matches: 55     partial matches: 0\n",
      "1510    full matches: 72     partial matches: 2\n",
      "1644    full matches: 54     partial matches: 0\n",
      "1772    full matches: 71     partial matches: 2\n",
      "1849    full matches: 70     partial matches: 2\n",
      "1859    full matches: 69     partial matches: 2\n",
      "1901    full matches: 68     partial matches: 2\n",
      "1907    full matches: 67     partial matches: 2\n",
      "1923    full matches: 66     partial matches: 2\n",
      "1971    full matches: 65     partial matches: 2\n",
      "1975    full matches: 64     partial matches: 2\n",
      "2000/10000 documents scanned\n",
      "2051    full matches: 63     partial matches: 2\n",
      "2059    full matches: 62     partial matches: 2\n",
      "2062    full matches: 61     partial matches: 2\n",
      "2103    full matches: 60     partial matches: 2\n",
      "2148    full matches: 59     partial matches: 2\n",
      "2180    full matches: 53     partial matches: 0\n",
      "2181    full matches: 52     partial matches: 0\n",
      "2183    full matches: 51     partial matches: 0\n",
      "2197    full matches: 50     partial matches: 0\n",
      "2199    full matches: 58     partial matches: 2\n",
      "2205    full matches: 57     partial matches: 2\n",
      "2206    full matches: 56     partial matches: 2\n",
      "2209    full matches: 55     partial matches: 2\n",
      "2309    full matches: 21     partial matches: 45\n",
      "2359    full matches: 54     partial matches: 2\n",
      "2427    full matches: 53     partial matches: 2\n",
      "2500/10000 documents scanned\n",
      "2514    full matches: 52     partial matches: 2\n",
      "2517    full matches: 51     partial matches: 2\n",
      "2527    full matches: 50     partial matches: 2\n",
      "2578    full matches: 49     partial matches: 2\n",
      "2589    full matches: 48     partial matches: 2\n",
      "3000/10000 documents scanned\n",
      "3234    full matches: 20     partial matches: 40\n",
      "3329    full matches: 19     partial matches: 40\n",
      "3339    full matches: 18     partial matches: 40\n",
      "3500/10000 documents scanned\n",
      "3880    full matches: 17     partial matches: 39\n",
      "4000/10000 documents scanned\n",
      "4033    full matches: 16     partial matches: 38\n",
      "4113    full matches: 15     partial matches: 38\n",
      "4117    full matches: 14     partial matches: 38\n",
      "4500/10000 documents scanned\n",
      "5000/10000 documents scanned\n",
      "5077    full matches: 176     partial matches: 0\n",
      "5080    full matches: 175     partial matches: 0\n",
      "5081    full matches: 174     partial matches: 0\n",
      "5083    full matches: 173     partial matches: 0\n",
      "5109    full matches: 66     partial matches: 0\n",
      "5117    full matches: 71     partial matches: 0\n",
      "5129    full matches: 54     partial matches: 0\n",
      "5146    full matches: 65     partial matches: 0\n",
      "5155    full matches: 64     partial matches: 0\n",
      "5200    full matches: 172     partial matches: 0\n",
      "5211    full matches: 63     partial matches: 0\n",
      "5225    full matches: 62     partial matches: 0\n",
      "5248    full matches: 171     partial matches: 0\n",
      "5250    full matches: 170     partial matches: 0\n",
      "5252    full matches: 169     partial matches: 0\n",
      "5257    full matches: 168     partial matches: 0\n",
      "5262    full matches: 167     partial matches: 0\n",
      "5267    full matches: 166     partial matches: 0\n",
      "5271    full matches: 46     partial matches: 8\n",
      "5273    full matches: 165     partial matches: 0\n",
      "5282    full matches: 61     partial matches: 0\n",
      "5316    full matches: 53     partial matches: 0\n",
      "5319    full matches: 52     partial matches: 0\n",
      "5334    full matches: 164     partial matches: 0\n",
      "5339    full matches: 163     partial matches: 0\n",
      "5343    full matches: 162     partial matches: 0\n",
      "5349    full matches: 161     partial matches: 0\n",
      "5372    full matches: 160     partial matches: 0\n",
      "5393    full matches: 159     partial matches: 0\n",
      "5394    full matches: 158     partial matches: 0\n",
      "5400    full matches: 60     partial matches: 0\n",
      "5403    full matches: 70     partial matches: 0\n",
      "5404    full matches: 69     partial matches: 0\n",
      "5426    full matches: 157     partial matches: 0\n",
      "5428    full matches: 45     partial matches: 8\n",
      "5429    full matches: 156     partial matches: 0\n",
      "5430    full matches: 44     partial matches: 8\n",
      "5437    full matches: 155     partial matches: 0\n",
      "5440    full matches: 154     partial matches: 0\n",
      "5445    full matches: 7     partial matches: 44\n",
      "5459    full matches: 68     partial matches: 0\n",
      "5475    full matches: 153     partial matches: 0\n",
      "5484    full matches: 152     partial matches: 0\n",
      "5500/10000 documents scanned\n",
      "5509    full matches: 151     partial matches: 0\n",
      "5515    full matches: 150     partial matches: 0\n",
      "5517    full matches: 149     partial matches: 0\n",
      "5520    full matches: 148     partial matches: 0\n",
      "5522    full matches: 59     partial matches: 0\n",
      "5525    full matches: 58     partial matches: 0\n",
      "5532    full matches: 57     partial matches: 0\n",
      "5539    full matches: 56     partial matches: 0\n",
      "5542    full matches: 67     partial matches: 0\n",
      "5558    full matches: 55     partial matches: 0\n",
      "5561    full matches: 147     partial matches: 0\n",
      "5564    full matches: 54     partial matches: 0\n",
      "5579    full matches: 53     partial matches: 0\n",
      "5583    full matches: 51     partial matches: 0\n",
      "5584    full matches: 50     partial matches: 0\n",
      "5589    full matches: 52     partial matches: 0\n",
      "5592    full matches: 66     partial matches: 0\n",
      "5597    full matches: 43     partial matches: 7\n",
      "5612    full matches: 51     partial matches: 0\n",
      "5619    full matches: 65     partial matches: 0\n",
      "5636    full matches: 80     partial matches: 0\n",
      "5642    full matches: 64     partial matches: 0\n",
      "5646    full matches: 63     partial matches: 0\n",
      "5648    full matches: 62     partial matches: 0\n",
      "5662    full matches: 61     partial matches: 0\n",
      "5664    full matches: 60     partial matches: 0\n",
      "5673    full matches: 50     partial matches: 0\n",
      "5698    full matches: 79     partial matches: 0\n",
      "5700    full matches: 78     partial matches: 0\n",
      "5725    full matches: 77     partial matches: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5733    full matches: 76     partial matches: 0\n",
      "5740    full matches: 75     partial matches: 0\n",
      "5751    full matches: 146     partial matches: 0\n",
      "5762    full matches: 74     partial matches: 0\n",
      "5784    full matches: 145     partial matches: 0\n",
      "5787    full matches: 144     partial matches: 0\n",
      "5818    full matches: 59     partial matches: 0\n",
      "5822    full matches: 143     partial matches: 0\n",
      "5858    full matches: 142     partial matches: 0\n",
      "5885    full matches: 141     partial matches: 0\n",
      "5891    full matches: 140     partial matches: 0\n",
      "5892    full matches: 139     partial matches: 0\n",
      "5901    full matches: 138     partial matches: 0\n",
      "5902    full matches: 137     partial matches: 0\n",
      "5917    full matches: 136     partial matches: 0\n",
      "5918    full matches: 58     partial matches: 0\n",
      "5957    full matches: 57     partial matches: 0\n",
      "5960    full matches: 56     partial matches: 0\n",
      "5968    full matches: 73     partial matches: 0\n",
      "5998    full matches: 55     partial matches: 0\n",
      "6000/10000 documents scanned\n",
      "6005    full matches: 72     partial matches: 0\n",
      "6010    full matches: 71     partial matches: 0\n",
      "6024    full matches: 135     partial matches: 0\n",
      "6026    full matches: 134     partial matches: 0\n",
      "6055    full matches: 133     partial matches: 0\n",
      "6063    full matches: 132     partial matches: 0\n",
      "6069    full matches: 131     partial matches: 0\n",
      "6118    full matches: 54     partial matches: 0\n",
      "6130    full matches: 70     partial matches: 0\n",
      "6157    full matches: 130     partial matches: 0\n",
      "6160    full matches: 129     partial matches: 0\n",
      "6164    full matches: 128     partial matches: 0\n",
      "6165    full matches: 127     partial matches: 0\n",
      "6169    full matches: 126     partial matches: 0\n",
      "6171    full matches: 125     partial matches: 0\n",
      "6189    full matches: 124     partial matches: 0\n",
      "6212    full matches: 123     partial matches: 0\n",
      "6213    full matches: 122     partial matches: 0\n",
      "6215    full matches: 121     partial matches: 0\n",
      "6219    full matches: 120     partial matches: 0\n",
      "6237    full matches: 119     partial matches: 0\n",
      "6268    full matches: 118     partial matches: 0\n",
      "6312    full matches: 53     partial matches: 0\n",
      "6315    full matches: 52     partial matches: 0\n",
      "6324    full matches: 51     partial matches: 0\n",
      "6369    full matches: 69     partial matches: 0\n",
      "6374    full matches: 68     partial matches: 0\n",
      "6391    full matches: 67     partial matches: 0\n",
      "6393    full matches: 66     partial matches: 0\n",
      "6405    full matches: 65     partial matches: 0\n",
      "6408    full matches: 64     partial matches: 0\n",
      "6419    full matches: 50     partial matches: 0\n",
      "6452    full matches: 117     partial matches: 0\n",
      "6466    full matches: 63     partial matches: 0\n",
      "6496    full matches: 62     partial matches: 0\n",
      "6500/10000 documents scanned\n",
      "6510    full matches: 61     partial matches: 0\n",
      "6511    full matches: 60     partial matches: 0\n",
      "6517    full matches: 59     partial matches: 0\n",
      "6636    full matches: 116     partial matches: 0\n",
      "6698    full matches: 115     partial matches: 0\n",
      "6734    full matches: 114     partial matches: 0\n",
      "6738    full matches: 113     partial matches: 0\n",
      "6739    full matches: 112     partial matches: 0\n",
      "6760    full matches: 111     partial matches: 0\n",
      "6761    full matches: 110     partial matches: 0\n",
      "6770    full matches: 109     partial matches: 0\n",
      "6774    full matches: 108     partial matches: 0\n",
      "6780    full matches: 107     partial matches: 0\n",
      "6786    full matches: 106     partial matches: 0\n",
      "6787    full matches: 105     partial matches: 0\n",
      "6824    full matches: 104     partial matches: 0\n",
      "6854    full matches: 103     partial matches: 0\n",
      "6909    full matches: 102     partial matches: 0\n",
      "6943    full matches: 101     partial matches: 0\n",
      "6996    full matches: 58     partial matches: 0\n",
      "6997    full matches: 57     partial matches: 0\n",
      "7000/10000 documents scanned\n",
      "7012    full matches: 56     partial matches: 0\n",
      "7027    full matches: 55     partial matches: 0\n",
      "7045    full matches: 100     partial matches: 0\n",
      "7046    full matches: 54     partial matches: 0\n",
      "7048    full matches: 53     partial matches: 0\n",
      "7066    full matches: 52     partial matches: 0\n",
      "7067    full matches: 51     partial matches: 0\n",
      "7085    full matches: 50     partial matches: 0\n",
      "7189    full matches: 99     partial matches: 0\n",
      "7242    full matches: 98     partial matches: 0\n",
      "7249    full matches: 97     partial matches: 0\n",
      "7254    full matches: 96     partial matches: 0\n",
      "7258    full matches: 95     partial matches: 0\n",
      "7316    full matches: 94     partial matches: 0\n",
      "7320    full matches: 93     partial matches: 0\n",
      "7328    full matches: 92     partial matches: 0\n",
      "7376    full matches: 91     partial matches: 0\n",
      "7390    full matches: 90     partial matches: 0\n",
      "7500/10000 documents scanned\n",
      "7511    full matches: 89     partial matches: 0\n",
      "7530    full matches: 88     partial matches: 0\n",
      "7531    full matches: 87     partial matches: 0\n",
      "7532    full matches: 86     partial matches: 0\n",
      "7533    full matches: 85     partial matches: 0\n",
      "7539    full matches: 84     partial matches: 0\n",
      "7554    full matches: 83     partial matches: 0\n",
      "7600    full matches: 82     partial matches: 0\n",
      "7672    full matches: 81     partial matches: 0\n",
      "7702    full matches: 80     partial matches: 0\n",
      "7711    full matches: 79     partial matches: 0\n",
      "7838    full matches: 78     partial matches: 0\n",
      "7884    full matches: 77     partial matches: 0\n",
      "7929    full matches: 76     partial matches: 0\n",
      "7931    full matches: 75     partial matches: 0\n",
      "7958    full matches: 74     partial matches: 0\n",
      "8000/10000 documents scanned\n",
      "8000    full matches: 73     partial matches: 0\n",
      "8013    full matches: 72     partial matches: 0\n",
      "8016    full matches: 71     partial matches: 0\n",
      "8025    full matches: 70     partial matches: 0\n",
      "8050    full matches: 69     partial matches: 0\n",
      "8160    full matches: 68     partial matches: 0\n",
      "8165    full matches: 67     partial matches: 0\n",
      "8174    full matches: 66     partial matches: 0\n",
      "8176    full matches: 65     partial matches: 0\n",
      "8179    full matches: 64     partial matches: 0\n",
      "8184    full matches: 63     partial matches: 0\n",
      "8186    full matches: 62     partial matches: 0\n",
      "8189    full matches: 61     partial matches: 0\n",
      "8268    full matches: 60     partial matches: 0\n",
      "8276    full matches: 59     partial matches: 0\n",
      "8297    full matches: 58     partial matches: 0\n",
      "8308    full matches: 57     partial matches: 0\n",
      "8383    full matches: 56     partial matches: 0\n",
      "8500/10000 documents scanned\n",
      "8513    full matches: 55     partial matches: 0\n",
      "8560    full matches: 54     partial matches: 0\n",
      "8585    full matches: 53     partial matches: 0\n",
      "8662    full matches: 52     partial matches: 0\n",
      "8664    full matches: 51     partial matches: 0\n",
      "8672    full matches: 50     partial matches: 0\n",
      "9000/10000 documents scanned\n",
      "9500/10000 documents scanned\n"
     ]
    }
   ],
   "source": [
    "#Now we are ready to compare all documents by their signatures, instead of by their content.\n",
    "\n",
    "#We will consider that if two documents have similarity == 1.0 they are a full signature match, and if two documents have 0.2 < similarity < 1.0 they are a partial signature match. In both cases, this may mean the documents are duplicates or near duplicates.\n",
    "\n",
    "#Write code to compare all pairs of documents. Use the following template:\n",
    "\n",
    "is_possible_duplicate = {}\n",
    "saved = 0\n",
    "# Iterate through all documents\n",
    "for docid1 in range(len(messages)):\n",
    "\n",
    "     # Do not examine again a document that is a possible duplicate\n",
    "    if docid not in is_possible_duplicate:\n",
    "\n",
    "        # Counters for full and partial signature matches\n",
    "        count_sig_full_matches = 0\n",
    "        count_sig_partial_matches = 0\n",
    "\n",
    "        # Extract the signature of the doc1\n",
    "        signature1 = extract_signature(docid1)\n",
    "        if docid1 % 500 == 0:\n",
    "            print(\"%d/%d documents scanned\" % (docid1, len(messages)))\n",
    "\n",
    "        # Iterate through documents with docid larger than doc1\n",
    "        for docid2 in range(docid1+1, len(messages)):\n",
    "\n",
    "            # If this has not already been marked as duplicate of another document\n",
    "            if docid2 not in is_possible_duplicate:\n",
    "\n",
    "                # Extract signature of doc2\n",
    "                signature2 = extract_signature(docid2)\n",
    "\n",
    "                if jaccard_similarity(signature1,signature2) == 1.0:\n",
    "                    is_possible_duplicate[docid1] = docid2\n",
    "                    count_sig_full_matches = count_sig_full_matches +1\n",
    "                elif jaccard_similarity(signature1,signature2) >0.2 and jaccard_similarity(signature1,signature2) <1.0:\n",
    "                    is_possible_duplicate[docid1] = docid2\n",
    "                    count_sig_partial_matches = count_sig_partial_matches + 1\n",
    "                    \n",
    "                if count_sig_partial_matches == 55:\n",
    "                    saved == docid2\n",
    "                # REPLACE THIS COMMENT WITH YOUR CODE:\n",
    "                # - Increase count_sig_full_matches and count_sig_partial_matches as needed\n",
    "                # - Include docid2 in is_possible_duplicate if needed\n",
    "\n",
    "        # REPLACE THIS COMMENT WITH YOUR CODE\n",
    "        # - If the number of partial matches plus full matches exceeds a threshold\n",
    "        #   print the document doc1 and indicate how many matches of each type it has\n",
    "        num_match = count_sig_full_matches + count_sig_partial_matches\n",
    "        if num_match >= 50:\n",
    "            print(docid1,\"   full matches:\", count_sig_full_matches, \"    partial matches:\", count_sig_partial_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with a brief commentary, based on the results above, about one tweet that has a substantial number of complete matches, but few partial matches. Include the full text of the original tweet. Comment on why you believe this tweet is not being changed much when copied or re-tweeted.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @emergenciescat: Què puc fer i que no? FAQs del #coronavirus a 14 de març. si us plau, demanem difusió. https://t.co/D5HNxwYjwK\n"
     ]
    }
   ],
   "source": [
    "print(messages[5077])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This is a public concern message regarding the corona virus pandemic which reasonably attracted attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"red\">Replace this cell with a brief commentary, based on the results above, about one tweet that has a substantial number of partial matches, but fewer complete matches. Include the full text of the original tweet and one near duplicate (that cannot be identical to the original tweet).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @salutcat: Quines mesures de prevenció cal seguir per evitar la propagació del 🦠 #coronavirus SARS-CoV-2 👇\n",
      "\n",
      "🔗 https://t.co/NS41dWDi9O ht…\n"
     ]
    }
   ],
   "source": [
    "print(messages[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELIVER (individually)\n",
    "\n",
    "Remember to read the section on \"delivering your code\" in the [course evaluation guidelines](https://github.com/chatox/data-mining-course/blob/master/upf/upf-evaluation.md).\n",
    "\n",
    "Deliver a zip file containing:\n",
    "\n",
    "* This notebook\n",
    "\n",
    "## Extra points available\n",
    "\n",
    "For more learning and extra points, compare what happens with 3 different ngram sizes (2-grams, 3-grams, 4-grams) in terms of the efficiency (speed) and effectiveness (accuracy). You can include plots for efficiency, and examples for effectiveness.\n",
    "\n",
    "**Note:** if you go for the extra points, add ``<font size=\"+2\" color=\"blue\">Additional results: various ngram sizes</font>`` at the top of your notebook.\n",
    "\n",
    "<font size=\"-1\" color=\"gray\">(Remove this cell when delivering.)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+2\" color=\"#003300\">I hereby declare that, except for the code provided by the course instructors, all of my code, report, and figures were produced by myself.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
